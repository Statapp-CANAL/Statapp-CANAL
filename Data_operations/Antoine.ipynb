{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_antoine = \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/\"\n",
    "path_results_antoine = \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from Tool_Functions.cleaning_data import *\n",
    "from Tool_Functions.join_data import *\n",
    "from Tool_Functions.test_comportment_reabo import *\n",
    "from Tool_Functions.visual import *\n",
    "from Tool_Functions.comportment_reabo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajout_anciennete(data_path, data_path_results):\n",
    "    df = file_to_dataframe(data_path + 'df_Données_Reabos_odd_new_v2.csv')\n",
    "    df['DATE_ACTE_REEL'] = pd.to_datetime(df['DATE_ACTE_REEL'])\n",
    "    date_plus_ancienne = df.groupby('ID_ABONNE')['DATE_ACTE_REEL'].min()\n",
    "    date_reference = pd.to_datetime('2023-10-30')\n",
    "    df['PREMIERE_APPARITION'] = df['ID_ABONNE'].map(date_plus_ancienne)\n",
    "    df['ANCIENNETE'] = (date_reference - df['PREMIERE_APPARITION']).dt.days\n",
    "    save_to_csv_file(df, data_path + 'df_Données_Reabos_odd_final.csv')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Statapp-CANAL-1/Data_operations/Tool_Functions/cleaning_data.py:14: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  datas = pd.read_csv(filenames,delimiter=st)\n"
     ]
    }
   ],
   "source": [
    "df1 = file_to_dataframe(path_antoine + 'df_Donnees_Reabos_odd_new_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['DATE_ACTE_REEL'] = pd.to_datetime(df1['DATE_ACTE_REEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_plus_ancienne = df1.groupby('ID_ABONNE')['DATE_ACTE_REEL'].min()\n",
    "date_reference = pd.to_datetime('2023-10-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['PREMIERE_APPARITION'] = df1['ID_ABONNE'].map(date_plus_ancienne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ANCIENNETE'] = (date_reference - df1['PREMIERE_APPARITION']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_to_csv_file(df1, path_antoine + 'df_Données_Reabos_odd_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = file_to_dataframe(path_antoine + 'fusion_table_score_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = file_to_dataframe(path_antoine + 'new_datas_diff_%.csv')\n",
    "df = new_df.drop(columns = ['NB_APPARITIONS', 'MOY_DELAI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.DataFrame(df).set_index('ID_ABONNE')\n",
    "columns_names = df_original.columns\n",
    "columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que df est votre DataFrame et qu'il contient des valeurs 'inf'\n",
    "# Remplacer 'inf' par NaN pour le traitement ultérieur\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer la colonne ID_ABONNE\n",
    "df_id = df[['ID_ABONNE']].copy()\n",
    "\n",
    "# Séparer les données à normaliser (sans la colonne ID_ABONNE)\n",
    "df_to_scale = df.drop(columns=['ID_ABONNE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mise à l'échelle des données sans ID_ABONNE\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_to_scale.fillna(0)), columns=df_to_scale.columns)\n",
    "\n",
    "# Concaténation de la colonne ID_ABONNE avec les données normalisées\n",
    "df_scaled = pd.concat([df_id, df_scaled], axis=1)\n",
    "df_scaled[np.isnan(df)] = -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modèle KMeans avec un nombre déterminé de clusters\n",
    "kmeans = KMeans(n_clusters=7) \n",
    "kmeans.fit(df_scaled)\n",
    "clusters = kmeans.labels_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamètres : \n",
    "init : Méthode d'initialisation des centroïdes. Les options courantes sont 'k-means++' (défaut), 'random', un tableau donné de formes (n_clusters, n_features) ou une méthode d'initialisation personnalisée. 'k-means++' choisit les centroïdes initiaux pour le clustering k-means d'une manière qui accélère la convergence.\n",
    "\n",
    "n_init : Nombre de fois où l'algorithme k-means sera exécuté avec différentes graines de centroïde. Les résultats finaux seront la meilleure sortie de n_init exécutions consécutives en termes d'inertie.\n",
    "\n",
    "max_iter : Le nombre maximal d'itérations de l'algorithme k-means pour une seule exécution.\n",
    "tol : Tolérance pour déclarer la convergence. Si les changements dans les centroïdes sont inférieurs à cette tolérance, l'algorithme peut arrêter plus tôt.\n",
    "\n",
    "precompute_distances : Détermine si les distances entre les points doivent être précalculées ou calculées à la volée. Cela peut accélérer les choses mais peut aussi consommer beaucoup de mémoire pour les grands ensembles de données.\n",
    "verbose : Mode verbeux.\n",
    "\n",
    "random_state : Graine utilisée par le générateur de nombres aléatoires pour l'initialisation du centroïde ou si init est une graine pour l'algorithme k-means++.\n",
    "\n",
    "copy_x : Si True (par défaut), les données d'entrée sont copiées, sinon elles peuvent être écrasées pendant le clustering.\n",
    "\n",
    "algorithm : Choix de l'algorithme pour calculer les k-moyens parmi 'auto', 'full' ou 'elkan'. Le choix classique 'full' est l'algorithme EM pour le k-means. 'elkan' est une variante plus efficace qui est plus rapide sur les ensembles de données avec de nombreux clusters mais qui ne fonctionne pas avec des métriques autres que la distance euclidienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster_KMeans'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "compte = df.groupby('Cluster_KMeans').count()\n",
    "compte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_\n",
    "centroids\n",
    "# Convertir les centroïdes en DataFrame pour une meilleure lisibilité\n",
    "centroids_df = pd.DataFrame(centroids, columns=columns_names)\n",
    "# Afficher les centroïdes\n",
    "print(centroids_df)\n",
    "save_to_csv_file(centroids_df, path_antoine + 'centres_clusters.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_df = pd.DataFrame(df_scaled, columns=columns_names)\n",
    "df_scaled_df['Cluster_KMeans'] = kmeans.labels_\n",
    "k = 7\n",
    "for i in range(k):\n",
    "    print(f\"Cluster {i} characteristics:\")\n",
    "    cluster_data = df_scaled_df[df_scaled_df['Cluster_KMeans'] == i]\n",
    "    # Vous pouvez ici calculer des statistiques ou des graphiques pour comprendre chaque cluster\n",
    "    print(cluster_data.describe())  # Résumé statistique\n",
    "    save_to_csv_file(cluster_data.describe(), path_antoine + 'cluster_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
