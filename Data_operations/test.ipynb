{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_antoine = \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/\"\n",
    "path_results_antoine = \"/Users/antoine/Documents/ENSAE2A/Codeperso/everything/Statappperso/Ressources/Results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from Tool_Functions.cleaning_data import *\n",
    "from Tool_Functions.join_data import *\n",
    "from Tool_Functions.test_comportment_reabo import *\n",
    "from Tool_Functions.visual import *\n",
    "from Tool_Functions.comportment_reabo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans  # Import KMeans clustering algorithm\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score  # Import silhouette metrics\n",
    "\n",
    "import matplotlib.cm as cm  # Import colormap for visualizations\n",
    "import matplotlib.pyplot as plt  # Import plotting library\n",
    "import numpy as np  \n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages  # Import PdfPages for saving plots to PDF\n",
    "\n",
    "# Scales the data set\n",
    "\n",
    "def cluster_data_set(filename, columns, change_inf=np.nan, change_nan=15):\n",
    "    \"\"\"\n",
    "    Load a dataset, perform clustering, and return clustered data.\n",
    "\n",
    "    Args:\n",
    "    - filename: Name of the file containing the data.\n",
    "    - columns: List of column names to include in clustering.\n",
    "    - change_inf: Value to use for replacing infinity.\n",
    "    - change_nan: Value to use for replacing NaN.\n",
    "\n",
    "    Returns:\n",
    "    - data: DataFrame containing clustered data.\n",
    "    \"\"\"\n",
    "    # Load the dataset from file\n",
    "    df = file_to_dataframe(filename)\n",
    "    \n",
    "    # Select the specified columns\n",
    "    data = df[columns]\n",
    "    \n",
    "    # Replace infinite values with specified value\n",
    "    data.replace([np.inf, -np.inf], change_inf, inplace=True)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    datas = scaler.fit_transform(data)\n",
    "    data = pd.DataFrame(datas, columns=data.columns)\n",
    "\n",
    "    # Select a random 10% sample of the data\n",
    "    indices = np.random.choice(range(len(data)), size=int(len(data) * 0.1), replace=False)\n",
    "    data = data.iloc[indices]\n",
    "\n",
    "    # Replace NaN values with specified value\n",
    "    data.replace(np.nan, change_nan, inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Après avoir utilisé KMeans et avoir obtenu clusters = ...\n",
    "\n",
    "def data_frame_cluster(data, columns, centers_inv, clusters, data_id_abo):\n",
    "    \"\"\"\n",
    "    Create a DataFrame containing clusters, cluster centers, and subscriber IDs.\n",
    "\n",
    "    Args:\n",
    "    - data: DataFrame containing the data.\n",
    "    - columns: List of column names.\n",
    "    - centers_inv: Inverse cluster centers (denormalized).\n",
    "    - clusters: Cluster number assigned to each sample.\n",
    "    - data_id_abo: DataFrame containing subscriber IDs.\n",
    "\n",
    "    Returns:\n",
    "    - df_clusters: DataFrame containing clusters, centers, and percentage IDs.\n",
    "    \"\"\"\n",
    "    # Add cluster labels and subscriber IDs to the data\n",
    "    data['KMEANS'] = clusters\n",
    "    data['ID_ABONNE'] = data_id_abo['ID_ABONNE']\n",
    "\n",
    "    # Generate DataFrame with cluster information\n",
    "    df_clusters = percent_abo_conditions(data, 'KMEANS', 'ID_ABONNE')\n",
    "    df_clusters = df_clusters.sort_values(by='KMEANS')\n",
    "\n",
    "    # Round and assign cluster centers to the DataFrame\n",
    "    centers = np.round(centers_inv, decimals=2)\n",
    "    for j in range(len(columns)):\n",
    "        df_clusters[columns[j]] = [centers[i][j] for i in range(len(centers))]\n",
    "\n",
    "    return df_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_df_to_excel(df, file_name, sheet_name='Sheet1'):\n",
    "    \"\"\"\n",
    "    Write a DataFrame to an Excel file.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame to write to Excel.\n",
    "    - file_name: Name of the Excel file.\n",
    "    - sheet_name: Name of the sheet in the Excel file (default is 'Sheet1').\n",
    "    \"\"\"\n",
    "    # Create a writer with the specified file name\n",
    "    writer = pd.ExcelWriter(file_name, engine='xlsxwriter')\n",
    "\n",
    "    # Write the DataFrame to the specified sheet\n",
    "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # Save and close the Excel file\n",
    "    writer.save()\n",
    "\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_silhouette_datas_all(filename, columns, range_n_clusters, data_path_results, change_inf=np.nan, change_nan=15):\n",
    "    \"\"\"\n",
    "    Visualize silhouette scores for different numbers of clusters.\n",
    "\n",
    "    Args:\n",
    "    - filename: Name of the file containing the data.\n",
    "    - columns: List of column names to include in clustering.\n",
    "    - range_n_clusters: List of numbers of clusters to test.\n",
    "    - data_path_results: Path to save the results.\n",
    "    - change_inf: Value to use for replacing infinity.\n",
    "    - change_nan: Value to use for replacing NaN.\n",
    "\n",
    "    Returns:\n",
    "    - silhouette_scores: List of silhouette scores.\n",
    "    \"\"\"\n",
    "    # Load the dataset from file\n",
    "    df = file_to_dataframe(filename)\n",
    "    data = df[columns]\n",
    "    \n",
    "    # Replace infinite values with specified value\n",
    "    data.replace([np.inf, -np.inf], change_inf, inplace=True)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    datas = scaler.fit_transform(data)\n",
    "\n",
    "    data = pd.DataFrame(datas, columns=data.columns)\n",
    "\n",
    "    # Select a random 10% sample of the data\n",
    "    indices = np.random.choice(range(len(data)), size=int(len(data) * 0.1), replace=False)\n",
    "    data = data.iloc[indices]\n",
    "    data_id_abo = df[['ID_ABONNE']].iloc[indices]\n",
    "\n",
    "    # Replace NaN values with specified value\n",
    "    data.replace(np.nan, change_nan, inplace=True)\n",
    "\n",
    "    silhouette_scores = []\n",
    "\n",
    "    with PdfPages(data_path_results + \"silhouettes_scores.pdf\") as pdf:\n",
    "        for n_clusters in range_n_clusters:\n",
    "\n",
    "            # Initialize the clusterer with n_clusters value and a random generator\n",
    "            # seed of 10 for reproducibility.\n",
    "            clusterer = KMeans(n_clusters, random_state=10)\n",
    "            clusterer.fit(data)\n",
    "\n",
    "            centers = clusterer.cluster_centers_\n",
    "            centers_cluster = np.round(scaler.inverse_transform(centers), decimals=2)\n",
    "\n",
    "            # Create DataFrame with cluster information\n",
    "            df_cluster = data_frame_cluster(data, columns, scaler.inverse_transform(centers),\n",
    "                                             clusterer.labels_, data_id_abo)\n",
    "            \n",
    "            # Write cluster DataFrame to Excel\n",
    "            write_df_to_excel(df_cluster, data_path_results + \"cluster\" + str(n_clusters) + \".xlsx\", str(n_clusters))\n",
    "\n",
    "            cluster_labels = clusterer.fit_predict(data)\n",
    "\n",
    "            silhouette_avg = silhouette_score(data, cluster_labels)\n",
    "\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "            print(\n",
    "                \"For n_clusters =\", n_clusters,\n",
    "                \"The average silhouette_score is :\", silhouette_avg,\n",
    "            )\n",
    "\n",
    "            fig, ax1 = plt.subplots(1, 1)\n",
    "            fig.set_size_inches(9, 7)\n",
    "\n",
    "            ax1.set_xlim([-0.1, 1])\n",
    "            ax1.set_ylim([0, len(data) + (n_clusters + 1) * 10])\n",
    "\n",
    "            y_lower = 10\n",
    "            sample_silhouette_values = silhouette_samples(data, cluster_labels)\n",
    "\n",
    "            for i in range(n_clusters):\n",
    "\n",
    "                ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "                ith_cluster_silhouette_values.sort()\n",
    "                size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                y_upper = y_lower + size_cluster_i\n",
    "                color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "                ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color,\n",
    "                                  edgecolor=color, alpha=0.7)\n",
    "                ax1.text(-0.8, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "                y_lower = y_upper + 10\n",
    "\n",
    "            ax1.set_title(\"The silhouette plot for the various clusters.\" + str(n_clusters))\n",
    "            ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "            ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "            ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "            ax1.set_yticks([])\n",
    "            ax1.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            plt.close(fig)\n",
    "\n",
    "    return silhouette_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trace_silhouette_scores(silhouette_scores, abscisses):\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(abscisses, silhouette_scores, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('KMeans Silhouette Score')\n",
    "    plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "    plt.show()\n",
    "\n",
    "    plt.xticks(abscisses)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_silhouette_scores(visualize_silhouette_datas_all(path_antoine + \"fusion_table_score_v1.csv\",\n",
    "                                                       ['ODD 15 jours TC_MEAN_TIME_DIFF'],\n",
    "                                                       [2, 3, 4, 5],\n",
    "                                                       path_antoine + \"Clustering_results/\"), [2, 3, 4,5])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
